# Variant Calling Pipeline Benchmark

[![Snakemake](https://img.shields.io/badge/snakemake-â‰¥7.0.0-brightgreen.svg)](https://snakemake.readthedocs.io)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A reproducible benchmark analysis of state-of-the-art variant calling pipelines for coding sequence variant discovery.

## ğŸ“‹ Group Project Overview

This project reproduces and extends the benchmarking study from:
**Barbitoff et al. (2022)** - *Systematic benchmark of state-of-the-art variant calling pipelines identifies major factors affecting accuracy of coding sequence variant discovery*

**Key Objectives:**
- Reproduce variant calling benchmark on GIAB samples (HG001, HG002)
- Compare performance of 3 aligners and 3 variant callers
- Evaluate precision, recall, and F1-score using built-in ML tools (DeepVariant, GATK CNN)
- Provide fully reproducible Snakemake workflow

## ğŸ—ï¸ Project Structure
------------------
```
variant-calling-benchmark/
â”œâ”€â”€ workflows/ # Snakemake workflow definitions
â”œâ”€â”€ scripts/ # Helper scripts for each analysis step
â”œâ”€â”€ config/ # Configuration files
â”œâ”€â”€ data/ # Data directory (external data goes here)
â”œâ”€â”€ analysis/ # R notebooks and analysis code
â”œâ”€â”€ docs/ # Documentation
â”œâ”€â”€ results/ # Generated results (not in version control)
â””â”€â”€ environment.yml # Conda environment specification
```
-------------------

## ğŸš€ Quick Start

### Prerequisites
- Conda or Mamba
- Snakemake â‰¥7.0.0

### Installation
```bash
# Clone repository
git clone git@github.com:mtariqi/variant-calling-benchmark.git
cd variant-calling-benchmark

# Set up environment and download test data
bash scripts/setup_project.sh

# Run workflow
snakemake --cores 4 --use-conda
ğŸ‘¥ Team Members
Member 1: Atra Alimoradian - Data management & alignment pipelines

Member 2: Raghad Al-Ampudi - Variant calling & workflow development

Member 3: Md Tariqul Islam - Benchmarking analysis & ML insights

## ğŸ—‚ï¸ **File Structure with Ownership**

```
variant-calling-benchmark/
â”œâ”€â”€ ğŸ“ workflows/
â”‚   â”œâ”€â”€ main.smk                    (Member 2 - Integrator)
â”‚   â”œâ”€â”€ alignment.smk              (Member 1 - Owner)
â”‚   â”œâ”€â”€ variant_calling.smk        (Member 2 - Owner) 
â”‚   â”œâ”€â”€ benchmarking.smk           (Member 3 - Owner)
â”‚   â””â”€â”€ qc.smk                     (Member 1 - Owner)
â”œâ”€â”€ ğŸ“ scripts/
â”‚   â”œâ”€â”€ download_data.sh           (Member 1 - Owner)
â”‚   â”œâ”€â”€ setup_project.sh           (Member 2 - Owner)
â”‚   â”œâ”€â”€ alignment/                 (Member 1 - Owner)
â”‚   â”œâ”€â”€ variant_calling/           (Member 2 - Owner)
â”‚   â””â”€â”€ benchmarking/              (Member 3 - Owner)
â”œâ”€â”€ ğŸ“ config/
â”‚   â”œâ”€â”€ config.yaml                (Member 2 - Integrator)
â”‚   â”œâ”€â”€ alignment_config.yaml      (Member 1 - Owner)
â”‚   â”œâ”€â”€ calling_config.yaml        (Member 2 - Owner)
â”‚   â””â”€â”€ benchmark_config.yaml      (Member 3 - Owner)
â”œâ”€â”€ ğŸ“ analysis/
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ exploratory_analysis.R (Member 3 - Owner)
â”‚   â”‚   â”œâ”€â”€ performance_analysis.R (Member 3 - Owner)
â”‚   â”‚   â””â”€â”€ ml_analysis.R          (Member 3 - Owner)
â”‚   â””â”€â”€ plots/                     (Member 3 - Owner)
â”œâ”€â”€ ğŸ“ docs/
â”‚   â”œâ”€â”€ project_plan.md            (All - Collaborative)
â”‚   â”œâ”€â”€ task_allocation.md         (All - Collaborative)
â”‚   â””â”€â”€ final_report.Rmd           (Member 3 - Lead)
â””â”€â”€ environment.yml                (Member 2 - Owner)

```

ğŸ”§ Pipeline Components
Tools Evaluated
Aligners: BWA-MEM, Bowtie2 (local), Novoalign

Variant Callers: GATK HaplotypeCaller, DeepVariant, FreeBayes

ML Integration: DeepVariant (CNN), GATK CNN filtering

Benchmarking: hap.py, custom R analysis

Workflow
text
Raw Reads â†’ Alignment â†’ Variant Calling â†’ Filtering â†’ Benchmarking â†’ Analysis
    â†“           â†“           â†“           â†“         â†“         â†“
  FASTQ       BAM         VCF        Filtered  hap.py   R/ML Analysis
ğŸ“Š Expected Outcomes
Comparative performance ranking of 18 pipeline combinations

ML-powered variant calling vs traditional methods comparison

Reproducible Snakemake workflow for variant calling benchmarks

Comprehensive performance report with visualizations

ğŸ“ License
MIT License - see LICENSE file for details.# variant-calling-benchmark
Reproducible benchmark of variant calling pipelines using GIAB data - BINF6300 Group Project
